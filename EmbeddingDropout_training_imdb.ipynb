{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmbeddingDropout_training_imdb.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPeLO+O4zMDTXfy951YdrmA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnaujc91/experiments/blob/main/EmbeddingDropout_training_imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9tw7JJru1Fz"
      },
      "source": [
        "!pip install fastai==2.0.16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWLw1fvXu4Sn"
      },
      "source": [
        "from fastai.text.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKBkVNyqFHSo"
      },
      "source": [
        "class EmbeddingDropout(nn.Embedding):\n",
        "    \"Apply dropout with probability `embed_p` to an embedding layer.\"\n",
        "    def __init__(self, *args, embed_p, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.embed_p = embed_p\n",
        "\n",
        "    def forward(self, words, scale=None):\n",
        "        if self.training and self.embed_p != 0:\n",
        "            size = (self.weight.size(0),1)\n",
        "            mask = dropout_mask(self.weight.data, size, self.embed_p)\n",
        "            masked_embed = self.weight * mask\n",
        "        else: masked_embed = self.weight\n",
        "        if scale: masked_embed.mul_(scale)\n",
        "        return F.embedding(words, masked_embed, ifnone(self.padding_idx, -1), self.max_norm,\n",
        "                       self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
        "        \n",
        "class AWD_LSTM(Module):\n",
        "    \"AWD-LSTM inspired by https://arxiv.org/abs/1708.02182\"\n",
        "    initrange=0.1\n",
        "\n",
        "    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token=1, hidden_p=0.2, input_p=0.6, embed_p=0.1,\n",
        "                 weight_p=0.5, bidir=False):\n",
        "        store_attr('emb_sz,n_hid,n_layers,pad_token')\n",
        "        self.bs = 1\n",
        "        self.n_dir = 2 if bidir else 1\n",
        "        # NEW CODE: \n",
        "        self.encoder = EmbeddingDropout(vocab_sz, emb_sz, embed_p=embed_p, padding_idx=pad_token)\n",
        "        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
        "        # PREVIOUS CODE:\n",
        "        # self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
        "        # self.encoder_dp = EmbeddingDropout(self.encoder, embed_p)\n",
        "        # self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
        "        self.rnns = nn.ModuleList([self._one_rnn(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.n_dir,\n",
        "                                                 bidir, weight_p, l) for l in range(n_layers)])\n",
        "        self.input_dp = RNNDropout(input_p)\n",
        "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n",
        "        self.reset()\n",
        "\n",
        "        '''\n",
        "        IMPORTANT: As you can see previously the layer self.encoder was just used to create the layer self.encoder_dp.\n",
        "                   Now instead EmbeddingDropout directly inherits from nn.Embedding in order to avoid using self.encoder.\n",
        "                   Therefore now the code is more compact with the same functionality.\n",
        "        '''\n",
        "\n",
        "    def forward(self, inp, from_embeds=False):\n",
        "        bs,sl = inp.shape[:2] if from_embeds else inp.shape\n",
        "        if bs!=self.bs: self._change_hidden(bs)\n",
        "\n",
        "        output = self.input_dp(inp if from_embeds else self.encoder(inp))\n",
        "        new_hidden = []\n",
        "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
        "            output, new_h = rnn(output, self.hidden[l])\n",
        "            new_hidden.append(new_h)\n",
        "            if l != self.n_layers - 1: output = hid_dp(output)\n",
        "        self.hidden = to_detach(new_hidden, cpu=False, gather=False)\n",
        "        return output\n",
        "\n",
        "    def _change_hidden(self, bs):\n",
        "        self.hidden = [self._change_one_hidden(l, bs) for l in range(self.n_layers)]\n",
        "        self.bs = bs\n",
        "\n",
        "    def _one_rnn(self, n_in, n_out, bidir, weight_p, l):\n",
        "        \"Return one of the inner rnn\"\n",
        "        rnn = nn.LSTM(n_in, n_out, 1, batch_first=True, bidirectional=bidir)\n",
        "        return WeightDropout(rnn, weight_p)\n",
        "\n",
        "    def _one_hidden(self, l):\n",
        "        \"Return one hidden state\"\n",
        "        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir\n",
        "        return (one_param(self).new_zeros(self.n_dir, self.bs, nh), one_param(self).new_zeros(self.n_dir, self.bs, nh))\n",
        "\n",
        "    def _change_one_hidden(self, l, bs):\n",
        "        if self.bs < bs:\n",
        "            nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir\n",
        "            return tuple(torch.cat([h, h.new_zeros(self.n_dir, bs-self.bs, nh)], dim=1) for h in self.hidden[l])\n",
        "        if self.bs > bs: return (self.hidden[l][0][:,:bs].contiguous(), self.hidden[l][1][:,:bs].contiguous())\n",
        "        return self.hidden[l]\n",
        "\n",
        "    def reset(self):\n",
        "        \"Reset the hidden states\"\n",
        "        [r.reset() for r in self.rnns if hasattr(r, 'reset')]\n",
        "        self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEQjdg5ppksA",
        "outputId": "f47e8f61-0a3c-4833-dcaa-28af7c1d631c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "path = untar_data(URLs.IMDB_SAMPLE)\n",
        "imdb = pd.read_csv(path/'texts.csv')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbelD5x-pntn",
        "outputId": "8be6b3a6-44d8-4265-8764-ea9b06e99c5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "imdb_cls  = TextDataLoaders.from_df(imdb, text_col='text', label_col='label')\n",
        "imdb_lm = TextDataLoaders.from_df(imdb, text_col='text', is_lm=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku4-nJswujl5",
        "outputId": "028278bb-faaf-49f8-f5f5-4090b507a567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "config = {'bidir': False,\n",
        " 'emb_sz': 400,\n",
        " 'embed_p': 0.02,\n",
        " 'hidden_p': 0.15,\n",
        " 'input_p': 0.25,\n",
        " 'n_hid': 1152,\n",
        " 'n_layers': 3,\n",
        " 'out_bias': True,\n",
        " 'output_p': 0.1,\n",
        " 'pad_token': 1,\n",
        " 'tie_weights': True,\n",
        " 'weight_p': 0.2}; config"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bidir': False,\n",
              " 'emb_sz': 400,\n",
              " 'embed_p': 0.02,\n",
              " 'hidden_p': 0.15,\n",
              " 'input_p': 0.25,\n",
              " 'n_hid': 1152,\n",
              " 'n_layers': 3,\n",
              " 'out_bias': True,\n",
              " 'output_p': 0.1,\n",
              " 'pad_token': 1,\n",
              " 'tie_weights': True,\n",
              " 'weight_p': 0.2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUe1aprOwByw"
      },
      "source": [
        "for k in config.keys():\n",
        "    if k.endswith('_p'): config[k] *= 1.\n",
        "tie_weights,output_p,out_bias = map(config.pop, ['tie_weights', 'output_p', 'out_bias'])\n",
        "init = config.pop('init') if 'init' in config else None\n",
        "encoder = AWD_LSTM(7080, **config)\n",
        "enc = encoder.encoder if tie_weights else None\n",
        "decoder = LinearDecoder(7080, config['emb_sz'], output_p, tie_encoder=enc, bias=out_bias)\n",
        "model = SequentialRNN(encoder, decoder)\n",
        "# if init is None:\n",
        "#   mdl = model \n",
        "# else: model.apply(init)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71kMjVZr6O3I"
      },
      "source": [
        "url = URLs.WT103_FWD\n",
        "model_path = untar_data(url , c_key='model')\n",
        "fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFoeY7wi6uJC",
        "outputId": "0d0f40b0-6647-4594-ea9c-e64599e74862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "fnames"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Path('/root/.fastai/models/wt103-fwd/lstm_fwd.pth'),\n",
              " Path('/root/.fastai/models/wt103-fwd/itos_wt103.pkl')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kep6H5la9d7J"
      },
      "source": [
        "from fastai.text.learner import _get_text_vocab"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqfVEJUO8jk-",
        "outputId": "60f554ec-03c9-4e8d-c930-a96d93c8e907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "old_vocab = load_pickle(fnames[1])\n",
        "new_vocab = _get_text_vocab(imdb_lm)\n",
        "wgts = torch.load(fnames[0], map_location = lambda storage,loc: storage)\n",
        "wgts = match_embeds(wgts, old_vocab, new_vocab)\n",
        "del wgts['0.encoder_dp.emb.weight']\n",
        "load_ignore_keys(model, clean_raw_keys(wgts))\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeJJ1rEXxtdN",
        "outputId": "12f9efc9-4ef7-481c-85dc-a24a381d5611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(7080, 400, padding_idx=1)\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=7080, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkGOUfG5B26k"
      },
      "source": [
        "def awd_lstm_lm_split(model):\n",
        "    \"Split a RNN `model` in groups for differential learning rates.\"\n",
        "    groups = [nn.Sequential(rnn, dp) for rnn, dp in zip(model[0].rnns, model[0].hidden_dps)]\n",
        "    groups = L(groups + [nn.Sequential(model[0].encoder, model[1])])\n",
        "    return groups.map(params)\n",
        "\n",
        "def requires_grad_bool(m:nn.Module)->Optional[bool]:\n",
        "    ps = list(m.parameters())\n",
        "    return ps[0].requires_grad\n",
        "\n",
        "def trainable_layers(learn):\n",
        "  modules = [m for m in flatten_model(learn.model) if has_params(m)]\n",
        "  for it in modules:\n",
        "    print(f\"{requires_grad_bool(it)}  -- \",it)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFFz41Jdzt-k"
      },
      "source": [
        "learn = LMLearner(imdb_lm, model, loss_func=CrossEntropyLossFlat(), splitter=awd_lstm_lm_split, cbs = [ShowGraphCallback])\n",
        "learn.freeze()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd-NuHbhXfWZ",
        "outputId": "41022388-d065-4485-940c-934d7d937ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "trainable_layers(learn)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True  --  EmbeddingDropout(7080, 400, padding_idx=1)\n",
            "False  --  LSTM(400, 1152, batch_first=True)\n",
            "False  --  ParameterModule()\n",
            "False  --  LSTM(1152, 1152, batch_first=True)\n",
            "False  --  ParameterModule()\n",
            "False  --  LSTM(1152, 400, batch_first=True)\n",
            "False  --  ParameterModule()\n",
            "True  --  Linear(in_features=400, out_features=7080, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziuEkFbMAd0P",
        "outputId": "f4fb8a6f-b334-4055-bdd6-e4ca85ab7611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "learn.fit_one_cycle(10, 5e-3)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.743114</td>\n",
              "      <td>4.167778</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.593585</td>\n",
              "      <td>4.020850</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.405624</td>\n",
              "      <td>3.937854</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.240870</td>\n",
              "      <td>3.915782</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.119486</td>\n",
              "      <td>3.911188</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.040253</td>\n",
              "      <td>3.908193</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.956089</td>\n",
              "      <td>3.908798</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.910961</td>\n",
              "      <td>3.909264</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3.877555</td>\n",
              "      <td>3.908636</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>3.867923</td>\n",
              "      <td>3.908665</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcpL0BbpAjAU"
      },
      "source": [
        "learn.save_encoder('finetuned')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm8LFdchg2mM"
      },
      "source": [
        "vocab_sz  = 7080"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--OG_ok4fE6e",
        "outputId": "ab0ef807-9950-4f3e-acc6-b7b75c72aa4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "vocab = _get_text_vocab(imdb_cls)\n",
        "pad_idx, max_len, seq_len= 1, 72*20, 72\n",
        "n_out = get_c(imdb_cls)\n",
        "config = awd_lstm_clas_config.copy()\n",
        "for k in config.keys():\n",
        "    if k.endswith('_p'): config[k] *= 1.\n",
        "lin_ftrs = [50]\n",
        "ps = [0.1]*len(lin_ftrs)\n",
        "layers = [config['emb_sz'] * 3] + lin_ftrs + [n_out]\n",
        "ps = [config.pop('output_p')] + ps\n",
        "init = config.pop('init') if 'init' in config else None\n",
        "encoder = SentenceEncoder(seq_len, AWD_LSTM(vocab_sz, **config), pad_idx=pad_idx, max_len=max_len)\n",
        "model = SequentialRNN(encoder, PoolingLinearClassifier(layers, ps, bptt=72))\n",
        "model if init is None else model.apply(init)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): SentenceEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): EmbeddingDropout(7080, 400, padding_idx=1)\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): LinBnDrop(\n",
              "        (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): Dropout(p=0.4, inplace=False)\n",
              "        (2): Linear(in_features=1200, out_features=50, bias=False)\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): LinBnDrop(\n",
              "        (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): Dropout(p=0.1, inplace=False)\n",
              "        (2): Linear(in_features=50, out_features=2, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K_AOVLTnBM2",
        "outputId": "cf64ef1e-b390-49db-a38a-82aed75934f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "load_ignore_keys(model[0], clean_raw_keys(wgts))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bChXgvf9ioKS"
      },
      "source": [
        "def awd_lstm_clas_split(model):\n",
        "    \"Split a RNN `model` in groups for differential learning rates.\"\n",
        "    groups = [nn.Sequential(model[0].module.encoder)]\n",
        "    groups += [nn.Sequential(rnn, dp) for rnn, dp in zip(model[0].module.rnns, model[0].module.hidden_dps)]\n",
        "    groups = L(groups + [model[1]])\n",
        "    return groups.map(params)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZHJU2dDFzan"
      },
      "source": [
        "learn = TextLearner(imdb_cls, model, splitter=awd_lstm_clas_split, metrics=[accuracy])\n",
        "learn.freeze()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYXMQb10mDuO"
      },
      "source": [
        "learn = learn.load_encoder('finetuned')\n",
        "learn.freeze()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXHyZO-goy2d",
        "outputId": "2bf88e28-6ac2-402b-bd50-711455a75e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "trainable_layers(learn)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False  --  EmbeddingDropout(7080, 400, padding_idx=1)\n",
            "False  --  LSTM(400, 1152, batch_first=True)\n",
            "False  --  ParameterModule()\n",
            "False  --  LSTM(1152, 1152, batch_first=True)\n",
            "False  --  ParameterModule()\n",
            "False  --  LSTM(1152, 400, batch_first=True)\n",
            "False  --  ParameterModule()\n",
            "True  --  BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "True  --  Linear(in_features=1200, out_features=50, bias=False)\n",
            "True  --  BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "True  --  Linear(in_features=50, out_features=2, bias=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWhSlsnVr98H",
        "outputId": "6b817eba-9ff0-4b62-e9e8-3cc353205589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "learn.fit_one_cycle(12, 2e-3)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.861592</td>\n",
              "      <td>0.674129</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.798609</td>\n",
              "      <td>0.591213</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.751204</td>\n",
              "      <td>0.518458</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.717545</td>\n",
              "      <td>0.488107</td>\n",
              "      <td>0.785000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.697305</td>\n",
              "      <td>0.471035</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.670302</td>\n",
              "      <td>0.445871</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.653722</td>\n",
              "      <td>0.444563</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.640909</td>\n",
              "      <td>0.438950</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.629374</td>\n",
              "      <td>0.431928</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.621527</td>\n",
              "      <td>0.426410</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.605129</td>\n",
              "      <td>0.432016</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.598970</td>\n",
              "      <td>0.424943</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}